# Microsoft End of Support Scraper ğŸš€

Este projeto Ã© um **web scraper automatizado** desenvolvido em **Python** para coletar informaÃ§Ãµes sobre o **fim do ciclo de vida (End of Support)** de produtos Microsoft diretamente da **documentaÃ§Ã£o oficial**.  
Os dados coletados sÃ£o processados, versionados e armazenados em um **banco de dados SQL Server**, garantindo rastreabilidade e histÃ³rico de execuÃ§Ãµes.

---

## ğŸ“‹ Funcionalidades

- **Scraping Inteligente**  
  Coleta produtos Microsoft que perderÃ£o suporte nos **prÃ³ximos 5 anos**.

- **PersistÃªncia em SQL Server**  
  Armazena os dados de forma estruturada.

- **Controle de VersÃ£o**  
  Identifica se um produto jÃ¡ existe no banco e atualiza apenas quando hÃ¡ mudanÃ§a na data de fim de suporte.

- **Logs Detalhados**  
  GeraÃ§Ã£o de logs em arquivo (`scraper.log`) e no console para monitoramento de execuÃ§Ã£o e erros.

- **Rastreabilidade**  
  Tabela de execuÃ§Ãµes para auditar quando o scraper rodou e quantos registros foram processados.

---

## ğŸ› ï¸ Tecnologias Utilizadas

- Python 3.x  
- **BeautifulSoup4** â€“ Parsing de HTML  
- **Requests** â€“ RequisiÃ§Ãµes HTTP  
- **PyODBC** â€“ ConexÃ£o com SQL Server  
- **Python-dotenv** â€“ Gerenciamento de variÃ¡veis de ambiente  

---

## âš™ï¸ ConfiguraÃ§Ã£o e InstalaÃ§Ã£o

### 1ï¸âƒ£ PrÃ©-requisitos

- Python instalado  
- Driver ODBC para SQL Server  
  - Exemplo: **Microsoft ODBC Driver 17 for SQL Server**
- Banco de dados SQL Server disponÃ­vel

---

### 2ï¸âƒ£ InstalaÃ§Ã£o das DependÃªncias

```bash
pip install requests beautifulsoup4 pyodbc python-dotenv
```

## 3ï¸âƒ£ VariÃ¡veis de Ambiente

Crie um arquivo `.env` na raiz do projeto com as credenciais do banco de dados:

```env
DB_SERVER=seu_servidor
DB_NAME=seu_banco_de_dados
DB_USER=seu_usuario
DB_PASSWORD=sua_senha
DB_DRIVER={ODBC Driver 17 for SQL Server}
```

## ğŸ—„ï¸ Estrutura do Banco de Dados

O projeto utiliza duas tabelas principais para **persistÃªncia** e **auditoria** das execuÃ§Ãµes do scraper.

---

### ğŸ”¹ `execucoes_scraper`

ResponsÃ¡vel pelo controle e rastreabilidade das execuÃ§Ãµes do scraper:

- Data e hora da execuÃ§Ã£o  
- Status da execuÃ§Ã£o (sucesso ou erro)  
- Total de registros processados  

---

### ğŸ”¹ `produtos_endsupport`

Armazena as informaÃ§Ãµes referentes ao fim de suporte dos produtos Microsoft:

- Nome do produto  
- Ano de referÃªncia  
- Data exata do fim do suporte  
- Identificador da execuÃ§Ã£o relacionada  

> âš ï¸ **Importante**  
> Na primeira execuÃ§Ã£o, descomente o bloco de criaÃ§Ã£o de tabelas dentro da funÃ§Ã£o `criar_tabelas()`  
> ou crie as tabelas manualmente conforme a estrutura definida no cÃ³digo.

---

## ğŸš€ Como Executar

Execute o script principal do projeto:

```bash
python main.py
```

Durante a execuÃ§Ã£o, o scraper irÃ¡:

1. Validar a conexÃ£o com o SQL Server  
2. Percorrer as pÃ¡ginas oficiais da Microsoft referentes aos prÃ³ximos 5 anos  
3. Comparar os dados coletados com os registros existentes  
4. Inserir ou atualizar somente os registros alterados  
5. Registrar a execuÃ§Ã£o e exibir um resumo no console  

---

## ğŸ“ Logs e Monitoramento

Os logs sÃ£o gerados automaticamente em dois formatos:

### ğŸ”¹ Console
- Acompanhamento em tempo real da execuÃ§Ã£o  

### ğŸ”¹ Arquivo (`scraper.log`)
- HistÃ³rico completo de erros, warnings e informaÃ§Ãµes  
- Ideal para auditoria e depuraÃ§Ã£o  

---

## ğŸ“ˆ Boas PrÃ¡ticas e RecomendaÃ§Ãµes

- Executar o scraper via:
  - Task Scheduler (Windows)
  - Cron (Linux)
  - Azure Automation / Data Factory

- Integrar os dados com:
  - Power BI
  - Data Warehouse
  - Processos de governanÃ§a de TI

- Versionar alteraÃ§Ãµes no scraper junto com:
  - MudanÃ§as de layout da documentaÃ§Ã£o da Microsoft
  - Ajustes de regras de negÃ³cio

---

## ğŸ“„ LicenÃ§a

Projeto de uso **interno / educacional**.
